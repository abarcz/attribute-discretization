\section{Specyfikacja ogólna testów.}
 Testy zostały wykonane przy użyciu dwóch zbiorów danych - uczącego i testowego, zgodnie z następującym schematem:
\begin{enumerate}
	\item{Zbudowanie modelu dyskretyzacji na zbiorze uczącym}
	\item{Dyskretyzacja zbioru uczącego przy użyciu modelu dyskretyzacji}
	\item{Nauczenie klasyfikatora na zdyskretyzowanym zbiorze uczącym}
	\item{Dyskretyzacja zbioru testowego przy użyciu modelu dyskretyzacji}
	\item{Sprawdzenie jakości klasyfikacji na zdyskretyzowanym zbiorze uczącym}
\end{enumerate}
Dla uzyskania wiarygodnych wyników zastosowano we wszystkich eksperymentach walidację krzyżową. Do testów użyto zbiór danych pomiarowych opisujących procesy zachodzące na czujnikach chemicznych \cite{Gas:2012}. Zbiór danych składa się z próbek o 129 atrybutach o wartościach ciągłych, na potrzeby eksperymentów dyskretyzowano wszystkie bądź wybrane atrybuty. Ze względu na długi czas dyskretyzacji do eksperymentów wykorzystano tylko zbiór \emph{batch1.dat}, składający się ze 445 próbek o dość równomiernym rozkładzie 6ciu klas. W celu zmniejszenia czasu eksperymentów, próbowano przeprowadzać część eksperymentów dyskretyzując tylko atrybuty najistotniejsze z punktu widzenia klasy próbek, jednakże wyniki tych eksperymentów były mało interesujące, w związku z czym skupiono się na dyskretyzowaniu całego zbioru atrybutów. Zbiór wybranych atrybutów to: $V_{imp} = \{V2, V7, V11, V18, V20, V26, V51, V67\}$. Atrybuty te zostały wybrane przy użyciu drzewa decyzyjnego z pakietu \emph{rpart}.

\newpage
\begin{alltt}
rpart(V1 ~ ., gas1)
n= 445 

node), split, n, loss, yval, (yprob)
      * denotes terminal node

 1) root 445 347 2 (0.2 0.22 0.19 0.067 0.16 0.17)  
   2) V2< 31988.61 189  91 2 (0.048 0.52 0.43 0 0 0)  
     4) V51>=5.942954 89   2 2 (0 0.98 0.022 0 0 0) *
     5) V51< 5.942954 100  20 3 (0.09 0.11 0.8 0 0 0)  
      10) V26< 8863.391 21  10 2 (0.43 0.52 0.048 0 0 0)  
        20) V7< -1.138504 10   1 1 (0.9 0 0.1 0 0 0) *
        21) V7>=-1.138504 11   0 2 (0 1 0 0 0 0) *
      11) V26>=8863.391 79   0 3 (0 0 1 0 0 0) *
   3) V2>=31988.61 256 175 1 (0.32 0 0.0039 0.12 0.27 0.29)  
     6) V2< 194291.8 177  96 1 (0.46 0 0.0056 0.062 0.056 0.42)  
      12) V18>=7439.422 71   3 1 (0.96 0 0.014 0.028 0 0) *
      13) V18< 7439.422 106  32 6 (0.12 0 0 0.085 0.094 0.7)  
        26) V67< 5.20329 29  16 1 (0.45 0 0 0.1 0.34 0.1)  
          52) V20>=0.8470795 13   0 1 (1 0 0 0 0 0) *
          53) V20< 0.8470795 16   6 5 (0 0 0 0.19 0.62 0.19) *
        27) V67>=5.20329 77   6 6 (0 0 0 0.078 0 0.92) *
     7) V2>=194291.8 79  19 5 (0 0 0 0.24 0.76 0)  
      14) V11>=9.623032 21   2 4 (0 0 0 0.9 0.095 0) *
      15) V11< 9.623032 58   0 5 (0 0 0 0 1 0) *
\end{alltt}



\section{Naiwny klasyfikator Bayesa.}
Do testów wykorzystano naiwny klasyfikator Bayesa z pakietu \emph{e1071}. Klasyfikator Bayesa dla atrybutów o wartościach dyskretnych liczy bezpośrednio prawdopodobieństwa warunkowe, natomiast w przypadku atrybutów o wartościach ciągłych estymuje dla każdego atrybutu rozkład prawdopodobieństwa, co wiąże się z pewną niedokładnością predykcji. W związku z tym dobrze przeprowadzona dyskretyzacja atrybutu powinna polepszyć jakość klasyfikacji, dzięki uniknięciu estymacji rozkładu prawdopodobieństwa wartości atrybutu. W ramach eksperymentu przeprowadzono 5-krotną walidację krzyżową na zbiorze danych, wyniki zestawiono w tabeli~\ref{tab:bayes_full_set}. W tabeli~\ref{tab:bayes_min_entropy} zestawiono wyniki dla dyskretyzacji zstępującej i kryterium stopu wykorzystującego minimalny spadek entropii w obszarze interesujących wartości parametru (zadanego minimalnego spadku) wraz ze średnią ilością utworzonych przedziałów. Wyniki 5-krotnej walidacji krzyżowej na zbiorze danych z ograniczonym zbiorem dyskretyzowanych atrybutów zestawiono w tabeli~\ref{tab:bayes_reduced_set} - eksperymenty te dawały mniej interesujące wyniki w związku z czym skupiono się na eksperymentach dysretyzujących wszystkie dostępne atrybuty.

\begin{table}[h!]
\begin{center}
\begin{tabular}{lrrrr}
\toprule
metoda & kryterium stopu & parametr & średnia dokładność & odchylenie std \\
\midrule
--       & --								& -- & 0.7592 & 0.0306 \\
TopDown  & delta~(\ref{eq:delta_criterion}) & -- & 0.8498 & 0.0436 \\
TopDown  & minimalna wartość entropii       &0.18 & 0.8315 & 0.0286 \\
TopDown  & zadana ilość przedziałów         & 6  & 0.8352	& 0.0541 \\
BottomUp & maksymalna wartość $\chi^2$ 		& 0.01 & 0.3198 & 0.0226 \\
BottomUp & zadana ilość przedziałów         & 6  & 0.3423	& 0.0434 \\
\bottomrule
\end{tabular}
\caption{$V1 \sim .$, dokładność klasyfikacji - klasyfikator Bayesa, 5-krotna walidacja krzyżowa}
\label{tab:bayes_full_set}
\end{center}
\end{table}

\begin{table}[h!]
\begin{center}
\begin{tabular}{lrrrr}
\toprule
metoda & kryterium stopu & parametr & średnia dokładność & odchylenie std \\
\midrule
--       & --    							& -- & 0.8711 & 0.0435 \\
TopDown  & delta~(\ref{eq:delta_criterion}) & -- & 0.8835 & 0.0158 \\
BottomUp & maksymalna wartość $\chi^2$ 		& 0.01 & 0.3398 & 0.0926 \\
\bottomrule
\end{tabular}
\caption{$V1 \sim V_{imp}$, dokładność klasyfikacji - klasyfikator Bayesa, 5-krotna walidacja krzyżowa}
\label{tab:bayes_reduced_set}
\end{center}
\end{table}

\begin{table}[h!]
\begin{center}
\begin{tabular}{lrrr}
\toprule
min spadek entropii &  średnia dokładność &  odchylenie std & średnia ilość przedziałów \\
\midrule
0.20 & 0.8320 & 0.0514 & 1.82 \\
0.19 & 0.8074 & 0.0601 & 3.85 \\
0.18 & 0.8315 & 0.0286 & 4.03 \\
0.17 & 0.8300 & 0.0633 & 10.42 \\
0.16 & 0.8108 & 0.0681 & 15.46 \\
0.15 & 0.8143 & 0.0425 & 19.39 \\
0.14 & 0.8118 & 0.0510 & 28.46 \\
0.13 & 0.7745 & 0.0613 & 44.85 \\
0.12 & 0.7362 & 0.0682 & 66.90 \\
0.11 & 0.7271 & 0.0630 & 92.32 \\
0.10 & 0.6922 & 0.0385 & 123.52 \\
\bottomrule
\end{tabular}
\caption{$V1 \sim .$, dokładność klasyfikacji - klasyfikator Bayesa, 5-krotna walidacja krzyżowa, TopDown + MinEntropyDecreaseCriterion}
\label{tab:bayes_min_entropy}
\end{center}
\end{table}

\subsection{Porównanie działania metody wstępującej i zstępującej.}
Jakość dyskretyzacji wstępującej i zstępującej porównano dla zadanej liczby przedziałów dla każdego atrybutu. W tabeli~\ref{tab:bayes_td_bu_comp_full_set} zestawiono jakość klasyfikacji przy użyciu klasyfikatora Bayesa.

\begin{table}[h!]
\begin{center}
\begin{tabular}{lrr}
\toprule
metoda & średnia dokładność & odchylenie std \\
\midrule
--      & 0.7592	& 0.0306 \\
TopDown & 0.8352	& 0.0541	\\
BottomUp& 0.3423	& 0.0434	\\
\bottomrule
\end{tabular}
\caption{$V1 \sim .$, porównanie działania metody zstępującej i wstępującej, dokładność klasyfikacji - klasyfikator Bayesa, 5-krotna walidacja krzyżowa, zadana ilość przedziałów = 6}
\label{tab:bayes_td_bu_comp_full_set}
\end{center}
\end{table}

\newpage
\section{Wnioski.}
Dyskretyzacja okazała się najbardziej korzystna w przypadku zdyskretyzowania wszystkich atrybutów zbioru danych -- uzyskano dużą poprawę dokładności klasyfikacji przy użyciu dyskretyzacji zstępującej. W przypadku wybrania tylko najbardziej istotnych atrybutów skok jakościowy nie jest już tak widoczny, choć zauważalna jest pewna stabilizacja wyników -- mniejsze odchylenie standardowe. Prawdopodobnie wynika to z faktu, że duża ilość nieistotnych atrybutów mocno zaburza działanie klasyfikatora Bayesa i wskazuje na konieczność selekcji atrybutów przy praktycznej klasyfikacji danych. Dla kryterium zstępującego przetestowano trzy różne kryteria stopu -- wyniki wskazują, że najlepszym (a jednoczesnie najwygodniejszym w użyciu, bo bezparametrycznym) kryterium stop jest kryterium \emph{delta}, bardziej elastyczne od dwóch pozostałych, dopasowujące się lokalnie do analizowanego przedziału. Okazało się jednak, że dwa pozostałe kryteria -- minimalny próg spadku entropii oraz żądana ilość przedziałów uzyskały wyniki bardzo zbliżone do kryterium \emph{delta}. Wymagało to jednak optymalizacji wartości ich parametrów. Dla kryterium wstępującego nie udało się uzyskać dobrych wyników, mimo sprawdzenia działania algorytmu na publicznie dostępnych przykładach oraz eksperymentów z wartością parametru $\chi^{2}_{min}$. Słabe wyniki dyskretyzacji były spowodowane osiąganiem niskich wartości $\chi^2$ dla przyległych wartości. To powodowało zbyt częste łączenie przyległych przedziałów wartości. Przypuszczalnie analizowany zbiór danych kiepsko nadaje się do stosowania tej metody, co wskazuje na konieczność dobierania metody dyskretyzacji do analizowanego zbioru danych. 
